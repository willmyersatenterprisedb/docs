---
title: 'Backup on object stores'
originalFilePath: 'src/backup.md'
---

EDB Postgres Distributed for Kubernetes (PG4K-PGD) supports *online/hot backup* of
PGD clusters through physical backup and WAL archiving on an object store.
This means that the database is always up (no downtime required) and that
Point In Time Recovery is available.

## Common object stores

Multiple object store are supported, such as `AWS S3`, `Microsoft Azure Blob Storage`,
`Google Cloud Storage`, `MinIO Gateway`, or any S3 compatible provider.
Given that PG4K-PGD configures the connection with object stores by relying on
EDB Postgres for Kubernetes (PG4K), please refer to the [PG4K Cloud provider support](https://www.enterprisedb.com/docs/postgres_for_kubernetes/latest/backup_recovery/#cloud-provider-support)
documentation for additional depth.

!!! Important
    In the PG4K documentation you'll find the Cloud Provider configuration section
    available at `spec.backup.barmanObjectStore`. Note that in PG4K-PGD examples, the object store section is found at a 
    different path: `spec.backup.configuration.barmanObjectStore`.

## WAL archive

WAL archiving is the process that sends `WAL files` to the object storage, and it's essential to
execute *online/hot backups*, or Point in Time recovery (PITR).
In PG4K-PGD, each PGD Node will be set up to archive WAL files in the object store independently.

The WAL archive is defined in the PGDGroup `spec.backup.configuration.barmanObjectStore` stanza,
and is enabled as soon as a destination path and cloud credentials are set.
You can choose to compress WAL files before they are uploaded, and/or encrypt them.
Parallel WAL archiving can also be enabled.

```yaml
apiVersion: pgd.k8s.enterprisedb.io/v1beta1
kind: PGDGroup
[...]
spec:
  backup:
    configuration:
      barmanObjectStore:
        [...]
        wal:
          compression: gzip
          encryption: AES256
          maxParallel: 8
```

For further information, refer to the [PG4K WAL archiving](https://www.enterprisedb.com/docs/postgres_for_kubernetes/latest/backup_recovery/#wal-archiving) documentation.

## Scheduled backups

Scheduled backups are the recommended way to configure your backup strategy in PG4K-PGD.
When the PGDGroup `spec.backup.configuration.barmanObjectStore` stanza is configured, the operator will select one of the
PGD data nodes as the elected "Backup Node", for which it will automatically create a `Scheduled Backup` resource.

The `.spec.backup.cron.schedule` field allows you to define a cron schedule specification, expressed
in the [https://pkg.go.dev/github.com/robfig/cron#hdr-CRON_Expression_Format]\(Go `cron` package format).

```yaml
apiVersion: pgd.k8s.enterprisedb.io/v1beta1
kind: PGDGroup
[...]
spec:
  backup:
    cron:
      schedule: "0 0 0 * * *"
      backupOwnerReference: self
      suspend: false
      immediate: true
```

Scheduled Backups can be suspended if necessary by setting `.spec.backup.cron.suspend` to true. This will
prevent any new backup from being scheduled while the option is set to true.

In case you want to execute a backup as soon as the ScheduledBackup resource is created
you can set `.spec.backup.cron.immediate` to true.

`.spec.backupOwnerReference` indicates which ownerReference should be used
in the created backup resources. The choices are:

-   *none:* no owner reference for created backup objects
-   *self:* sets the Scheduled backup object as owner of the backup
-   *cluster:* sets the cluster as owner of the backup

!!! Note
    The `PG4K` ScheduledBackup object contains an additional option named `cluster` to specify the
    Cluster to be backed up. This option is currently not supported by `PG4K-PGD`, and will be
    ignored if specified.

In case an elected "Backup node" is deleted, the operator will transparently elect a new "Backup Node"
and reconcile the Scheduled Backup resource accordingly.

## Retention policies

PG4K-PGD can manage the automated deletion of backup files from the backup
object store, using **retention policies** based on the recovery window.
This process will also take care of removing unused WAL files and WALs associated with backups
that are scheduled for deletion.

You can define your backups with a retention policy of 30 days as follows:

```yaml
apiVersion: pgd.k8s.enterprisedb.io/v1beta1
kind: PGDGroup
[...]
spec:
  backup:
    configuration:
      retentionPolicy: "30d"
```

For further information, refer to the [PG4K Retention policies](https://www.enterprisedb.com/docs/postgres_for_kubernetes/latest/backup_recovery/#retention-policies) documentation.

!!! Important
    Currently, the retention policy will only be applied for the elected "Backup Node"
    backups and WAL files. Given that each other PGD node also archives its own WALs
    independently, it is your responsibility to manage the lifecycle of those WAL files,
    for example by leveraging the object storage data retention policy.
    Also, in case you have an object storage data retention policy set up on every PGD Node
    directory, make sure it's not overlapping or interfering with the retention policy managed
    by the operator.

## Compression algorithms

Backups and WAL files are uncompressed by default. However, multiple compression algorithms are
supported. For more information, refer to the [PG4K Compression algorithms](https://www.enterprisedb.com/docs/postgres_for_kubernetes/latest/backup_recovery/#compression-algorithms) documentation.

## Tagging of backup objects

It's possible to specify tags as key-value pairs for the backup objects, namely base backups, WAL files and history files.
For more information, refer to the [PG4K document on Tagging of backup objects](https://www.enterprisedb.com/docs/postgres_for_kubernetes/latest/backup_recovery/#tagging-of-backup-objects).

## On-demand backups of a PGD Node

A PGD Node is represented as single-instance PG4K `Cluster` object.
As such, in case of need, it's possible to request an on-demand backup
of a specific PGD Node by creating a PG4K `Backup` resource.
In order to do that, you can directly refer to the [PG4K On-demand backups](https://www.enterprisedb.com/docs/postgres_for_kubernetes/latest/backup_recovery/#on-demand-backups) documentation.

!!! Hint
    You can retrieve the list of PG4K Clusters that make up your PGDGroup
    by running: `kubectl get cluster -l k8s.pgd.enterprisedb.io/group=my-pgd-group -n my-namespace`